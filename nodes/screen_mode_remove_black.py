# MIT License
# 
# Copyright (c) 2024 Seed
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

import numpy as np
import torch


class ScreenModeRemoveBlackNode:
    """
    Screenæ¨¡å¼å»é»‘åº•èŠ‚ç‚¹ï¼Œæ¨¡æ‹ŸPhotoshopæ»¤è‰²å åŠ æ•ˆæœ
    å°†é»‘è‰²åŒºåŸŸè½¬æ¢ä¸ºé€æ˜æ¸å˜ï¼Œäº§ç”Ÿè‡ªç„¶çš„è¿‡æ¸¡æ•ˆæœ
    """

    @classmethod
    def INPUT_TYPES(cls):
        """
        å®šä¹‰èŠ‚ç‚¹çš„è¾“å…¥ç±»å‹

        è¿”å›:
            dict: è¾“å…¥å‚æ•°çš„å®šä¹‰
        """
        return {
            "required": {
                "image": ("IMAGE",),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "screen_mode_process"
    CATEGORY = "ComfyUI-Seed-Nodes"
    DESCRIPTION = "Screenæ¨¡å¼å»é»‘åº• - è·å–RGBä¸‰é€šé“æ•°æ®ï¼ŒæŒ‰é¡ºåºç”¨æ»¤è‰²æ¨¡å¼åˆæˆå»é™¤é»‘èƒŒæ™¯"

    def screen_mode_process(self, image):
        """
        ä½¿ç”¨Screenæ¨¡å¼ç®—æ³•å»é™¤é»‘åº•ï¼ŒæŒ‰ç…§æŒ‡å®šç®—æ³•å®ç°

        ç®—æ³•æµç¨‹:
        1. ä»æºå›¾è·å–R,G,Bä¸‰ä¸ªé€šé“å„è‡ªçš„å›¾åƒæ•°æ®
        2. æ¯ä¸ªé€šé“æ•°æ®éƒ½å¸¦alphaé€šé“(ä½¿ç”¨é€šé“å€¼ä½œä¸ºalpha)
        3. æŒ‰ç…§R,G,Bé¡ºåºç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        4. æœ€ç»ˆå¾—åˆ°å»æ‰é»‘èƒŒæ™¯çš„é€æ˜PNG

        å‚æ•°:
            image (torch.Tensor): è¾“å…¥å›¾åƒå¼ é‡

        è¿”å›:
            tuple: å¤„ç†åçš„å›¾åƒå¼ é‡
        """
        # ç¡®ä¿è¾“å…¥ä¸º torch.Tensor
        if not isinstance(image, torch.Tensor):
            image = torch.from_numpy(image)
        
        # ä¿å­˜åŸå§‹è®¾å¤‡å’Œæ•°æ®ç±»å‹ä¿¡æ¯
        device = image.device
        dtype = image.dtype
        batch_size = image.shape[0]
        
        # ç¡®ä¿åœ¨CPUä¸Šå¤„ç†
        image_cpu = image.cpu().float()
        results = []
        
        # é€æ‰¹æ¬¡å¤„ç†å›¾åƒ
        for b in range(batch_size):
            img_data = image_cpu[b].numpy()
            processed_img = self._apply_screen_mode(img_data)
            
            # è½¬æ¢å›å¼ é‡
            processed_tensor = torch.from_numpy(processed_img).to(device, dtype=dtype)
            results.append(processed_tensor)
        
        # å †å æ‰¹æ¬¡ç»“æœ
        return (torch.stack(results, dim=0),)

    def _apply_screen_mode(self, img_data):
        """
        åº”ç”¨Screenæ¨¡å¼æ ¸å¿ƒç®—æ³•ï¼ŒæŒ‰ç…§ç”¨æˆ·æè¿°çš„ç®—æ³•å®ç°

        å‚æ•°:
            img_data: å›¾åƒæ•°æ®æ•°ç»„ (H, W, C)

        è¿”å›:
            numpy.ndarray: å¤„ç†åçš„RGBAå›¾åƒæ•°æ®
        """
        height, width, channels = img_data.shape
        
        # å¤„ç†ä¸åŒé€šé“æ•°çš„å›¾åƒ
        if channels == 3:
            # RGBå›¾åƒï¼Œæ·»åŠ Alphaé€šé“
            alpha_channel = np.ones((height, width, 1), dtype=np.float32)
            img_data = np.concatenate([img_data, alpha_channel], axis=2)
        elif channels == 4:
            # RGBAå›¾åƒï¼Œç›´æ¥ä½¿ç”¨
            pass
        else:
            # ä¸æ”¯æŒçš„é€šé“æ•°ï¼Œè½¬æ¢ä¸ºRGB+Alpha
            if channels == 1:
                # ç°åº¦å›¾åƒ
                img_data = np.repeat(img_data, 3, axis=2)
            else:
                # å…¶ä»–æƒ…å†µï¼Œå–å‰3ä¸ªé€šé“
                img_data = img_data[:, :, :3]
            alpha_channel = np.ones((height, width, 1), dtype=np.float32)
            img_data = np.concatenate([img_data, alpha_channel], axis=2)

        # åˆ†ç¦»RGBAé€šé“
        red, green, blue, alpha = img_data[:,:,0], img_data[:,:,1], img_data[:,:,2], img_data[:,:,3]
        
        # æŒ‰ç…§ç”¨æˆ·ç®—æ³•ï¼š
        # 1. è·å–R,G,Bä¸‰ä¸ªé€šé“å„è‡ªçš„å›¾åƒæ•°æ®ï¼Œè¿™äº›æ•°æ®è¦å¸¦alphaé€šé“
        
        # Ré€šé“å›¾åƒæ•°æ®(å¸¦alpha)
        r_data = np.zeros((height, width, 4), dtype=np.float32)
        r_data[:,:,0] = red      # Ré€šé“
        r_data[:,:,1] = 0        # G=0
        r_data[:,:,2] = 0        # B=0  
        r_data[:,:,3] = red      # Alphaä½¿ç”¨Ré€šé“å€¼
        
        # Gé€šé“å›¾åƒæ•°æ®(å¸¦alpha)
        g_data = np.zeros((height, width, 4), dtype=np.float32)
        g_data[:,:,0] = 0        # R=0
        g_data[:,:,1] = green    # Gé€šé“
        g_data[:,:,2] = 0        # B=0
        g_data[:,:,3] = green    # Alphaä½¿ç”¨Gé€šé“å€¼
        
        # Bé€šé“å›¾åƒæ•°æ®(å¸¦alpha)
        b_data = np.zeros((height, width, 4), dtype=np.float32)
        b_data[:,:,0] = 0        # R=0
        b_data[:,:,1] = 0        # G=0
        b_data[:,:,2] = blue     # Bé€šé“
        b_data[:,:,3] = blue     # Alphaä½¿ç”¨Bé€šé“å€¼
        
        # 2. æŒ‰ç…§R,G,Bé¡ºåºç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        # æ»¤è‰²å…¬å¼: result = 1 - (1 - base) * (1 - blend)
        
        # ä»é»‘è‰²èƒŒæ™¯å¼€å§‹
        result = np.zeros((height, width, 4), dtype=np.float32)
        
        # ç¬¬ä¸€æ­¥ï¼šä¸Ré€šé“æ•°æ®æ»¤è‰²åˆæˆ
        result[:,:,0] = 1 - (1 - result[:,:,0]) * (1 - r_data[:,:,0])
        result[:,:,1] = 1 - (1 - result[:,:,1]) * (1 - r_data[:,:,1])
        result[:,:,2] = 1 - (1 - result[:,:,2]) * (1 - r_data[:,:,2])
        # Alphaé€šé“ä¹Ÿç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        result[:,:,3] = 1 - (1 - result[:,:,3]) * (1 - r_data[:,:,3])
        
        # ç¬¬äºŒæ­¥ï¼šä¸Gé€šé“æ•°æ®æ»¤è‰²åˆæˆ
        result[:,:,0] = 1 - (1 - result[:,:,0]) * (1 - g_data[:,:,0])
        result[:,:,1] = 1 - (1 - result[:,:,1]) * (1 - g_data[:,:,1])
        result[:,:,2] = 1 - (1 - result[:,:,2]) * (1 - g_data[:,:,2])
        # Alphaé€šé“ä¹Ÿç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        result[:,:,3] = 1 - (1 - result[:,:,3]) * (1 - g_data[:,:,3])
        
        # ç¬¬ä¸‰æ­¥ï¼šä¸Bé€šé“æ•°æ®æ»¤è‰²åˆæˆ
        result[:,:,0] = 1 - (1 - result[:,:,0]) * (1 - b_data[:,:,0])
        result[:,:,1] = 1 - (1 - result[:,:,1]) * (1 - b_data[:,:,1])
        result[:,:,2] = 1 - (1 - result[:,:,2]) * (1 - b_data[:,:,2])
        # Alphaé€šé“ä¹Ÿç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        result[:,:,3] = 1 - (1 - result[:,:,3]) * (1 - b_data[:,:,3])
        
        return result

    def get_info(self):
        """
        è¿”å›èŠ‚ç‚¹ä¿¡æ¯

        è¿”å›:
            str: èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯
        """
        return """
        ğŸ¬ Screenæ¨¡å¼å»é»‘åº•èŠ‚ç‚¹
        
        ç®—æ³•æµç¨‹:
        â€¢ ä»æºæ··é»‘èƒŒæ™¯çš„å›¾ä¸Šè·å–R,G,Bä¸‰ä¸ªé€šé“å„è‡ªçš„å›¾åƒæ•°æ®
        â€¢ è¿™äº›æ•°æ®ä¸€å®šè¦å¸¦alphaé€šé“(ä½¿ç”¨é€šé“å€¼ä½œä¸ºalpha)
        â€¢ æŒ‰ç…§R,G,Bçš„é¡ºåºç”¨æ»¤è‰²æ¨¡å¼åˆæˆ
        â€¢ æœ€ç»ˆå¾—åˆ°å»æ‰é»‘èƒŒæ™¯çš„é€æ˜PNGå›¾
        
        æŠ€æœ¯ç‰¹ç‚¹:
        â€¢ é›¶å‚æ•°è®¾è®¡ï¼Œå³æ’å³ç”¨
        â€¢ ä½¿ç”¨çœŸå®æ»¤è‰²å…¬å¼ 1-(1-base)*(1-blend)
        â€¢ Alphaé€šé“ä¹Ÿå‚ä¸æ»¤è‰²åˆæˆ
        â€¢ å®Œå…¨æŒ‰ç…§æŒ‡å®šç®—æ³•å®ç°
        
        ä½¿ç”¨åœºæ™¯:
        â€¢ åºåˆ—å¸§ç‰¹æ•ˆåˆæˆ
        â€¢ ç²’å­æ•ˆæœå åŠ   
        â€¢ å…‰æ•ˆå¤„ç†
        â€¢ ç«ç„°ã€çˆ†ç‚¸ç­‰ç‰¹æ•ˆ
        """ 